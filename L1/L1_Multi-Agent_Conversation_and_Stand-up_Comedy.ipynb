{"cells":[{"cell_type":"markdown","id":"a81456dd","metadata":{"id":"a81456dd"},"source":["# Lesson 1: Multi-Agent Conversation and Stand-up Comedy"]},{"cell_type":"markdown","id":"4693467e","metadata":{"id":"4693467e"},"source":["Welcome to Lesson 1.\n","\n","To access the `requirements.txt` file and the`utils` modules, please go to the `File` menu and select`Open...`.\n","\n","I hope you enjoy this course!"]},{"cell_type":"markdown","id":"742cf649","metadata":{"id":"742cf649"},"source":["## Setup"]},{"cell_type":"code","execution_count":null,"id":"S3FTKGZIAGrU","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":127629,"status":"ok","timestamp":1718865691417,"user":{"displayName":"nijil k","userId":"05216079438697605186"},"user_tz":-330},"id":"S3FTKGZIAGrU","outputId":"2b2f9a92-06d7-480a-a104-e7258da226d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pyautogen[gemini,lmm,retrievechat]\n","  Downloading pyautogen-0.2.29-py3-none-any.whl (290 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.2/290.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting diskcache (from pyautogen[gemini,lmm,retrievechat])\n","  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docker (from pyautogen[gemini,lmm,retrievechat])\n","  Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting flaml (from pyautogen[gemini,lmm,retrievechat])\n","  Downloading FLAML-2.1.2-py3-none-any.whl (296 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.7/296.7 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from pyautogen[gemini,lmm,retrievechat]) (1.25.2)\n","Collecting openai>=1.3 (from pyautogen[gemini,lmm,retrievechat])\n","  Downloading openai-1.35.1-py3-none-any.whl (326 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.8/326.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pyautogen[gemini,lmm,retrievechat]) (24.1)\n","Requirement already satisfied: pydantic!=2.6.0,<3,>=1.10 in /usr/local/lib/python3.10/dist-packages (from pyautogen[gemini,lmm,retrievechat]) (2.7.3)\n","Collecting python-dotenv (from pyautogen[gemini,lmm,retrievechat])\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from pyautogen[gemini,lmm,retrievechat]) (2.4.0)\n","Collecting tiktoken (from pyautogen[gemini,lmm,retrievechat])\n","  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (from pyautogen[gemini,lmm,retrievechat]) (2.27.0)\n","Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.10/dist-packages (from pyautogen[gemini,lmm,retrievechat]) (1.54.1)\n","Requirement already satisfied: google-generativeai<1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from pyautogen[gemini,lmm,retrievechat]) (0.5.4)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pyautogen[gemini,lmm,retrievechat]) (9.4.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from pyautogen[gemini,lmm,retrievechat]) (4.12.3)\n","Collecting chromadb (from pyautogen[gemini,lmm,retrievechat])\n","  Downloading chromadb-0.5.3-py3-none-any.whl (559 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m559.5/559.5 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from pyautogen[gemini,lmm,retrievechat]) (7.34.0)\n","Collecting markdownify (from pyautogen[gemini,lmm,retrievechat])\n","  Downloading markdownify-0.12.1-py3-none-any.whl (16 kB)\n","Collecting protobuf==4.25.3 (from pyautogen[gemini,lmm,retrievechat])\n","  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pypdf (from pyautogen[gemini,lmm,retrievechat])\n","  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sentence-transformers (from pyautogen[gemini,lmm,retrievechat])\n","  Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting replicate (from pyautogen[gemini,lmm,retrievechat])\n","  Downloading replicate-0.26.0-py3-none-any.whl (40 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: google-ai-generativelanguage==0.6.4 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<1,>=0.5->pyautogen[gemini,lmm,retrievechat]) (0.6.4)\n","Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<1,>=0.5->pyautogen[gemini,lmm,retrievechat]) (2.11.1)\n","Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<1,>=0.5->pyautogen[gemini,lmm,retrievechat]) (2.84.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<1,>=0.5->pyautogen[gemini,lmm,retrievechat]) (4.66.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<1,>=0.5->pyautogen[gemini,lmm,retrievechat]) (4.12.2)\n","Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.4->google-generativeai<1,>=0.5->pyautogen[gemini,lmm,retrievechat]) (1.23.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->pyautogen[gemini,lmm,retrievechat]) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth->pyautogen[gemini,lmm,retrievechat]) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth->pyautogen[gemini,lmm,retrievechat]) (4.9)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen[gemini,lmm,retrievechat]) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.3->pyautogen[gemini,lmm,retrievechat]) (1.7.0)\n","Collecting httpx<1,>=0.23.0 (from openai>=1.3->pyautogen[gemini,lmm,retrievechat])\n","  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen[gemini,lmm,retrievechat]) (1.3.1)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen[gemini,lmm,retrievechat]) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen[gemini,lmm,retrievechat]) (2.18.4)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->pyautogen[gemini,lmm,retrievechat]) (2.5)\n","Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb->pyautogen[gemini,lmm,retrievechat]) (1.2.1)\n","Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb->pyautogen[gemini,lmm,retrievechat]) (2.31.0)\n","Collecting chroma-hnswlib==0.7.3 (from chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fastapi>=0.95.2 (from chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting posthog>=2.4.0 (from chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading onnxruntime-1.18.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting opentelemetry-api>=1.2.0 (from chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading opentelemetry_api-1.25.0-py3-none-any.whl (59 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading opentelemetry_exporter_otlp_proto_grpc-1.25.0-py3-none-any.whl (18 kB)\n","Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading opentelemetry_instrumentation_fastapi-0.46b0-py3-none-any.whl (11 kB)\n","Collecting opentelemetry-sdk>=1.2.0 (from chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading opentelemetry_sdk-1.25.0-py3-none-any.whl (107 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb->pyautogen[gemini,lmm,retrievechat]) (0.19.1)\n","Collecting pypika>=0.48.9 (from chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading PyPika-0.48.9.tar.gz (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting overrides>=7.3.1 (from chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb->pyautogen[gemini,lmm,retrievechat]) (6.4.0)\n","Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->pyautogen[gemini,lmm,retrievechat]) (1.64.1)\n","Collecting bcrypt>=4.0.1 (from chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl (283 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->pyautogen[gemini,lmm,retrievechat]) (0.12.3)\n","Collecting kubernetes>=28.1.0 (from chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb->pyautogen[gemini,lmm,retrievechat]) (8.3.0)\n","Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->pyautogen[gemini,lmm,retrievechat]) (6.0.1)\n","Collecting mmh3>=4.0.1 (from chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting orjson>=3.9.12 (from chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker->pyautogen[gemini,lmm,retrievechat]) (2.0.7)\n","Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform->pyautogen[gemini,lmm,retrievechat]) (2.8.0)\n","Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform->pyautogen[gemini,lmm,retrievechat]) (3.21.0)\n","Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform->pyautogen[gemini,lmm,retrievechat]) (1.12.3)\n","Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform->pyautogen[gemini,lmm,retrievechat]) (2.0.4)\n","Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform->pyautogen[gemini,lmm,retrievechat]) (0.16)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->pyautogen[gemini,lmm,retrievechat]) (67.7.2)\n","Collecting jedi>=0.16 (from ipython->pyautogen[gemini,lmm,retrievechat])\n","  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->pyautogen[gemini,lmm,retrievechat]) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->pyautogen[gemini,lmm,retrievechat]) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->pyautogen[gemini,lmm,retrievechat]) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->pyautogen[gemini,lmm,retrievechat]) (3.0.47)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->pyautogen[gemini,lmm,retrievechat]) (2.16.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->pyautogen[gemini,lmm,retrievechat]) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->pyautogen[gemini,lmm,retrievechat]) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->pyautogen[gemini,lmm,retrievechat]) (4.9.0)\n","Requirement already satisfied: six<2,>=1.15 in /usr/local/lib/python3.10/dist-packages (from markdownify->pyautogen[gemini,lmm,retrievechat]) (1.16.0)\n","Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->pyautogen[gemini,lmm,retrievechat]) (4.41.2)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->pyautogen[gemini,lmm,retrievechat]) (2.3.0+cu121)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->pyautogen[gemini,lmm,retrievechat]) (1.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->pyautogen[gemini,lmm,retrievechat]) (1.11.4)\n","Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->pyautogen[gemini,lmm,retrievechat]) (0.23.3)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->pyautogen[gemini,lmm,retrievechat]) (2024.5.15)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.3->pyautogen[gemini,lmm,retrievechat]) (3.7)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.3->pyautogen[gemini,lmm,retrievechat]) (1.2.1)\n","Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb->pyautogen[gemini,lmm,retrievechat]) (1.1.0)\n","Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb->pyautogen[gemini,lmm,retrievechat]) (2.0.1)\n","Collecting starlette<0.38.0,>=0.37.2 (from fastapi>=0.95.2->chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi>=0.95.2->chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n","Requirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb->pyautogen[gemini,lmm,retrievechat]) (3.1.4)\n","Collecting python-multipart>=0.0.7 (from fastapi>=0.95.2->chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n","Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi>=0.95.2->chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi>=0.95.2->chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading email_validator-2.1.2-py3-none-any.whl (30 kB)\n","Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<1,>=0.5->pyautogen[gemini,lmm,retrievechat]) (1.63.1)\n","Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<1,>=0.5->pyautogen[gemini,lmm,retrievechat]) (1.48.2)\n","Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform->pyautogen[gemini,lmm,retrievechat]) (2.3.3)\n","Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform->pyautogen[gemini,lmm,retrievechat]) (2.7.0)\n","Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform->pyautogen[gemini,lmm,retrievechat]) (2.8.2)\n","Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform->pyautogen[gemini,lmm,retrievechat]) (0.13.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.3->pyautogen[gemini,lmm,retrievechat]) (2024.6.2)\n","Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>=1.3->pyautogen[gemini,lmm,retrievechat])\n","  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.3->pyautogen[gemini,lmm,retrievechat])\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers->pyautogen[gemini,lmm,retrievechat]) (3.14.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers->pyautogen[gemini,lmm,retrievechat]) (2023.6.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->pyautogen[gemini,lmm,retrievechat]) (0.8.4)\n","Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb->pyautogen[gemini,lmm,retrievechat]) (1.8.0)\n","Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb->pyautogen[gemini,lmm,retrievechat]) (1.3.1)\n","Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb->pyautogen[gemini,lmm,retrievechat]) (3.2.2)\n","Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb->pyautogen[gemini,lmm,retrievechat]) (24.3.25)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb->pyautogen[gemini,lmm,retrievechat]) (1.12.1)\n","Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n","Requirement already satisfied: importlib-metadata<=7.1,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb->pyautogen[gemini,lmm,retrievechat]) (7.1.0)\n","Collecting opentelemetry-exporter-otlp-proto-common==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading opentelemetry_exporter_otlp_proto_common-1.25.0-py3-none-any.whl (17 kB)\n","Collecting opentelemetry-proto==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading opentelemetry_proto-1.25.0-py3-none-any.whl (52 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading opentelemetry_instrumentation_asgi-0.46b0-py3-none-any.whl (14 kB)\n","Collecting opentelemetry-instrumentation==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading opentelemetry_instrumentation-0.46b0-py3-none-any.whl (29 kB)\n","Collecting opentelemetry-semantic-conventions==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl (130 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting opentelemetry-util-http==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading opentelemetry_util_http-0.46b0-py3-none-any.whl (6.9 kB)\n","Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->pyautogen[gemini,lmm,retrievechat]) (1.14.1)\n","Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->pyautogen[gemini,lmm,retrievechat]) (0.7.0)\n","Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n","Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->pyautogen[gemini,lmm,retrievechat]) (0.2.13)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth->pyautogen[gemini,lmm,retrievechat]) (0.6.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb->pyautogen[gemini,lmm,retrievechat]) (3.3.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->pyautogen[gemini,lmm,retrievechat]) (3.3)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers->pyautogen[gemini,lmm,retrievechat])\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers->pyautogen[gemini,lmm,retrievechat])\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers->pyautogen[gemini,lmm,retrievechat])\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence-transformers->pyautogen[gemini,lmm,retrievechat])\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence-transformers->pyautogen[gemini,lmm,retrievechat])\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence-transformers->pyautogen[gemini,lmm,retrievechat])\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence-transformers->pyautogen[gemini,lmm,retrievechat])\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence-transformers->pyautogen[gemini,lmm,retrievechat])\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence-transformers->pyautogen[gemini,lmm,retrievechat])\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.11.0->sentence-transformers->pyautogen[gemini,lmm,retrievechat])\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers->pyautogen[gemini,lmm,retrievechat])\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->pyautogen[gemini,lmm,retrievechat]) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers->pyautogen[gemini,lmm,retrievechat])\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers->pyautogen[gemini,lmm,retrievechat]) (0.4.3)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb->pyautogen[gemini,lmm,retrievechat]) (8.1.7)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb->pyautogen[gemini,lmm,retrievechat]) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb->pyautogen[gemini,lmm,retrievechat]) (13.7.1)\n","Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<1,>=0.5->pyautogen[gemini,lmm,retrievechat]) (0.22.0)\n","Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<1,>=0.5->pyautogen[gemini,lmm,retrievechat]) (0.1.1)\n","Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<1,>=0.5->pyautogen[gemini,lmm,retrievechat]) (4.1.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers->pyautogen[gemini,lmm,retrievechat]) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers->pyautogen[gemini,lmm,retrievechat]) (3.5.0)\n","Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi>=0.95.2->chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform->pyautogen[gemini,lmm,retrievechat]) (1.5.0)\n","Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client->google-generativeai<1,>=0.5->pyautogen[gemini,lmm,retrievechat]) (3.1.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.1,>=6.0->opentelemetry-api>=1.2.0->chromadb->pyautogen[gemini,lmm,retrievechat]) (3.19.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.2->fastapi>=0.95.2->chromadb->pyautogen[gemini,lmm,retrievechat]) (2.1.5)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb->pyautogen[gemini,lmm,retrievechat]) (3.0.0)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb->pyautogen[gemini,lmm,retrievechat])\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb->pyautogen[gemini,lmm,retrievechat]) (1.3.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb->pyautogen[gemini,lmm,retrievechat]) (0.1.2)\n","Building wheels for collected packages: pypika\n","  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=b574173e433ea2736b76bb3fdddfcc4c446a1ccf830cb7a86a958a3233b9fb5a\n","  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n","Successfully built pypika\n","Installing collected packages: pypika, monotonic, mmh3, websockets, uvloop, ujson, python-multipart, python-dotenv, pypdf, protobuf, overrides, orjson, opentelemetry-util-http, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jedi, humanfriendly, httptools, h11, flaml, dnspython, diskcache, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, uvicorn, tiktoken, starlette, posthog, opentelemetry-proto, opentelemetry-api, nvidia-cusparse-cu12, nvidia-cudnn-cu12, markdownify, httpcore, email_validator, docker, coloredlogs, opentelemetry-semantic-conventions, opentelemetry-instrumentation, opentelemetry-exporter-otlp-proto-common, onnxruntime, nvidia-cusolver-cu12, kubernetes, httpx, replicate, opentelemetry-sdk, opentelemetry-instrumentation-asgi, openai, fastapi-cli, sentence-transformers, pyautogen, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, fastapi, chromadb\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.20.3\n","    Uninstalling protobuf-3.20.3:\n","      Successfully uninstalled protobuf-3.20.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.1.3 chroma-hnswlib-0.7.3 chromadb-0.5.3 coloredlogs-15.0.1 deprecated-1.2.14 diskcache-5.6.3 dnspython-2.6.1 docker-7.1.0 email_validator-2.1.2 fastapi-0.111.0 fastapi-cli-0.0.4 flaml-2.1.2 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 humanfriendly-10.0 jedi-0.19.1 kubernetes-30.1.0 markdownify-0.12.1 mmh3-4.1.0 monotonic-1.6 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 onnxruntime-1.18.0 openai-1.35.1 opentelemetry-api-1.25.0 opentelemetry-exporter-otlp-proto-common-1.25.0 opentelemetry-exporter-otlp-proto-grpc-1.25.0 opentelemetry-instrumentation-0.46b0 opentelemetry-instrumentation-asgi-0.46b0 opentelemetry-instrumentation-fastapi-0.46b0 opentelemetry-proto-1.25.0 opentelemetry-sdk-1.25.0 opentelemetry-semantic-conventions-0.46b0 opentelemetry-util-http-0.46b0 orjson-3.10.5 overrides-7.7.0 posthog-3.5.0 protobuf-4.25.3 pyautogen-0.2.29 pypdf-4.2.0 pypika-0.48.9 python-dotenv-1.0.1 python-multipart-0.0.9 replicate-0.26.0 sentence-transformers-3.0.1 starlette-0.37.2 tiktoken-0.7.0 ujson-5.10.0 uvicorn-0.30.1 uvloop-0.19.0 watchfiles-0.22.0 websockets-12.0\n"]}],"source":["!pip install pyautogen[gemini,retrievechat,lmm]"]},{"cell_type":"code","execution_count":null,"id":"04d006c1-22fa-40ea-b3e0-d543142e0788","metadata":{"id":"04d006c1-22fa-40ea-b3e0-d543142e0788"},"outputs":[],"source":["# from utils import get_openai_api_key\n","# OPENAI_API_KEY = get_openai_api_key()\n","# llm_config = {\"model\": \"gpt-3.5-turbo\"}\n","\n","from google.colab import userdata\n","GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n","\n","llm_config = {\n","        \"model\": \"gemini-pro\",\n","        \"api_key\": GEMINI_API_KEY, #\"your Google's GenAI Key goes here\",\n","        \"api_type\": \"google\"\n","    }"]},{"cell_type":"markdown","id":"116a1c4d","metadata":{"id":"116a1c4d"},"source":["## Define an AutoGen agent"]},{"cell_type":"code","execution_count":null,"id":"6fb8c441-c58c-41a8-a54b-5c387afceac5","metadata":{"colab":{"background_save":true},"id":"6fb8c441-c58c-41a8-a54b-5c387afceac5"},"outputs":[],"source":["from autogen import ConversableAgent\n","\n","agent = ConversableAgent(\n","    name=\"chatbot\",\n","    llm_config=llm_config,\n","    human_input_mode=\"NEVER\",\n",")"]},{"cell_type":"code","execution_count":null,"id":"47886b5f-fc7c-431a-8036-cff6e88f85c6","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"elapsed":6526,"status":"ok","timestamp":1718625583800,"user":{"displayName":"nijil k","userId":"05216079438697605186"},"user_tz":-330},"id":"47886b5f-fc7c-431a-8036-cff6e88f85c6","outputId":"5e29e81e-5e59-4299-8612-b7dd590c27a0"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'content': 'Why did the scarecrow win an award?\\n\\nBecause he was outstanding in his field!', 'role': 'assistant', 'function_call': None, 'tool_calls': None}\n"]}],"source":["reply = agent.generate_reply(\n","    messages=[{\"content\": \"Tell me a joke.\", \"role\": \"user\"}]\n",")\n","print(reply)"]},{"cell_type":"code","execution_count":null,"id":"67f626e9-4cec-40c1-abde-2eff1252b848","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":5942,"status":"ok","timestamp":1718625623900,"user":{"displayName":"nijil k","userId":"05216079438697605186"},"user_tz":-330},"id":"67f626e9-4cec-40c1-abde-2eff1252b848","outputId":"6377965f-24f8-4c0a-8cc8-3c406c74cb50"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'content': 'I am sorry, but there is no joke provided for me to repeat.', 'role': 'assistant', 'function_call': None, 'tool_calls': None}\n"]}],"source":["reply = agent.generate_reply(\n","    messages=[{\"content\": \"Repeat the joke.\", \"role\": \"user\"}]\n",")\n","print(reply)"]},{"cell_type":"markdown","id":"favV_rA_FXbS","metadata":{"id":"favV_rA_FXbS"},"source":["generate_reply doesn't update the internal state! so it won't repeat the joke"]},{"cell_type":"markdown","id":"8c98a301","metadata":{"id":"8c98a301"},"source":["## Conversation\n","\n","Setting up a conversation between two agents, Cathy and Joe, where the memory of their interactions is retained."]},{"cell_type":"code","execution_count":5,"id":"8f109dcb-824e-40d7-8e86-efee42b75f3c","metadata":{"executionInfo":{"elapsed":1595,"status":"ok","timestamp":1718865769633,"user":{"displayName":"nijil k","userId":"05216079438697605186"},"user_tz":-330},"id":"8f109dcb-824e-40d7-8e86-efee42b75f3c"},"outputs":[],"source":["cathy = ConversableAgent(\n","    name=\"cathy\",\n","    system_message=\n","    \"Your name is Cathy and you are a stand-up comedian.\",\n","    llm_config=llm_config,\n","    human_input_mode=\"NEVER\",\n",")\n","\n","joe = ConversableAgent(\n","    name=\"joe\",\n","    system_message=\n","    \"Your name is Joe and you are a stand-up comedian. \"\n","    \"Start the next joke from the punchline of the previous joke.\",\n","    llm_config=llm_config,\n","    human_input_mode=\"NEVER\",\n",")"]},{"cell_type":"markdown","id":"43f71a61","metadata":{"id":"43f71a61"},"source":["**Note**: You might get a slightly different response (set of jokes) than what is shown in the video"]},{"cell_type":"code","execution_count":null,"id":"46a1c6f6-687e-40de-8819-374201cfed9f","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":46400,"status":"ok","timestamp":1718626032212,"user":{"displayName":"nijil k","userId":"05216079438697605186"},"user_tz":-330},"id":"46a1c6f6-687e-40de-8819-374201cfed9f","outputId":"f6cce2e5-db81-43cf-9592-cda03d8ac748"},"outputs":[{"name":"stdout","output_type":"stream","text":["joe (to cathy):\n","\n","I'm Joe. Cathy, let's keep the jokes rolling.\n","\n","--------------------------------------------------------------------------------\n","cathy (to joe):\n","\n","**Cathy:** Thanks, Joe! I'm glad to be here. So, I was thinking about the other day when I went to the grocery store. I was looking for some bananas, and I finally found them. But when I got to the checkout, the cashier said, \"Those bananas are too ripe.\" I said, \"I know, but I'm not going to eat them. I'm going to use them to make banana bread.\" She said, \"That's a good idea. I love banana bread.\" I said, \"Yeah, me too. Especially when it's made with overripe bananas.\" She said, \"Why?\" I said, \"Because then it tastes like it's already been eaten.\"\n","\n","**Joe:** That's a good one!\n","\n","**Cathy:** Thanks! I've got another one for you. So, I was talking to my friend the other day about how I'm always getting lost. She said, \"Cathy, you need to get a GPS.\" I said, \"I have a GPS.\" She said, \"Well, then how do you keep getting lost?\" I said, \"Because I'm always losing it.\"\n","\n","**Joe:** That's hilarious!\n","\n","**Cathy:** Thanks! I'm glad you're enjoying them.\n","\n","**Joe:** Keep them coming!\n","\n","**Cathy:** Sure thing! So, I was at the doctor's office the other day, and the doctor said to me, \"Cathy, you need to lose some weight.\" I said, \"I know, but I'm not going to lose it. I'm going to gain it.\" He said, \"Why?\" I said, \"Because I'm trying to get to the bottom of this.\"\n","\n","--------------------------------------------------------------------------------\n","joe (to cathy):\n","\n","**Joe:** That's a great one! I love how you turned the doctor's advice on its head.\n","\n","**Cathy:** Thanks, Joe! I'm glad you enjoyed it. Here's another one for you:\n","\n","I was at the grocery store the other day, and I saw a sign that said, \"Buy one, get one 50% off.\" So I bought two of everything.\n","\n","**Joe:** That's hilarious! I can just imagine you walking out of the store with two carts full of groceries.\n","\n","**Cathy:** You got it, Joe! Here's another one:\n","\n","I was at the doctor's office the other day, and the doctor said to me, \"Cathy, you need to lose some weight.\" I said, \"I know, but I'm not going to lose it. I'm going to gain it.\" He said, \"Why?\" I said, \"Because I'm trying to get to the bottom of this.\"\n","\n","**Joe:** That's a great one! I love how you turned the doctor's advice on its head.\n","\n","**Cathy:** Thanks, Joe! I'm glad you enjoyed it. Here's another one for you:\n","\n","I was at the beauty salon the other day, and the stylist said to me, \"Cathy, you have a lot of split ends.\" I said, \"I know, but I'm not going to cut them. I'm going to grow them out.\" She said, \"Why?\" I said, \"Because I'm trying to get to the root of the problem.\"\n","\n","**Joe:** That's hilarious! I love how you're always finding the humor in everyday situations.\n","\n","**Cathy:** Thanks, Joe! I'm glad you're enjoying them. Here's another one for you:\n","\n","I was at the bank the other day, and the teller said to me, \"Cathy, you have a lot of money in your account.\" I said, \"I know, but I'm not going to spend it. I'm going to save it.\" She said, \"Why?\" I said, \"Because I'm trying to get to the bottom of this.\"\n","\n","**Joe:** That's a great one! I love how you're always turning the tables on people.\n","\n","**Cathy:** Thanks, Joe! I'm glad you're enjoying them. Here's another one for you:\n","\n","I was at the car dealership the other day, and the salesman said to me, \"Cathy, you need a new car.\" I\n","\n","--------------------------------------------------------------------------------\n","cathy (to joe):\n","\n","**Cathy:** Thanks, Joe! I'm glad you enjoyed it. Here's another one for you:\n","\n","I was at the car dealership the other day, and the salesman said to me, \"Cathy, you need a new car.\" I said, \"I know, but I'm not going to buy one. I'm going to keep my old one.\" He said, \"Why?\" I said, \"Because I'm trying to get to the bottom of this.\"\n","\n","**Joe:** That's hilarious! I love how you're always finding the humor in everyday situations.\n","\n","**Cathy:** Thanks, Joe! I'm glad you're enjoying them. Here's another one for you:\n","\n","I was at the library the other day, and the librarian said to me, \"Cathy, you have a lot of overdue books.\" I said, \"I know, but I'm not going to return them. I'm going to keep them.\" She said, \"Why?\" I said, \"Because I'm trying to get to the bottom of this.\"\n","\n","**Joe:** That's a great one! I love how you're always turning the tables on people.\n","\n","**Cathy:** Thanks, Joe! I'm glad you're enjoying them. Here's another one for you:\n","\n","I was at the doctor's office the other day, and the doctor said to me, \"Cathy, you need to lose some weight.\" I said, \"I know, but I'm not going to lose it. I'm going to gain it.\" He said, \"Why?\" I said, \"Because I'm trying to get to the bottom of this.\"\n","\n","**Joe:** That's hilarious! I love how you're always finding the humor in everyday situations.\n","\n","**Cathy:** Thanks, Joe! I'm glad you're enjoying them. Here's another one for you:\n","\n","I was at the beauty salon the other day, and the stylist said to me, \"Cathy, you have a lot of split ends.\" I said, \"I know, but I'm not going to cut them. I'm going to grow them out.\" She said, \"Why?\" I said, \"Because I'm trying to get to the root of the problem.\"\n","\n","**Joe:** That's a great one! I love how you're always turning the tables on people.\n","\n","**Cathy:** Thanks, Joe! I'm glad you're enjoying them. Here's another one for you:\n","\n","I was at the bank the other day, and the teller said to me, \"Cathy, you have a lot of money in your account.\" I said, \"I know, but I'm not going to spend it. I'm going to save it.\" She said, \"Why?\" I said, \"Because I'm trying to get to the bottom of this.\"\n","\n","**Joe:** That's hilarious! I love how you're always finding the humor in everyday situations.\n","\n","**Cathy:** Thanks, Joe! I'm glad you're enjoying them. Here's another one for you:\n","\n","I was at the grocery store the other day, and I saw a sign that said, \"Buy one, get one 50% off.\" So I bought two of everything.\n","\n","--------------------------------------------------------------------------------\n"]}],"source":["chat_result = joe.initiate_chat(\n","    recipient=cathy,\n","    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\",\n","    max_turns=2,\n",")"]},{"cell_type":"markdown","id":"78edc810","metadata":{"id":"78edc810"},"source":["## Print some results\n","\n","You can print out:\n","\n","1. Chat history\n","2. Cost\n","3. Summary of the conversation"]},{"cell_type":"code","execution_count":null,"id":"1169ea24-eadd-4909-8d56-9b7ec5677c66","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":508,"status":"ok","timestamp":1718626113814,"user":{"displayName":"nijil k","userId":"05216079438697605186"},"user_tz":-330},"id":"1169ea24-eadd-4909-8d56-9b7ec5677c66","outputId":"def5b55a-244b-498d-f81b-57ad0fa1ed2a"},"outputs":[{"name":"stdout","output_type":"stream","text":["[{'content': \"I'm Joe. Cathy, let's keep the jokes rolling.\",\n","  'role': 'assistant'},\n"," {'content': \"**Cathy:** Thanks, Joe! I'm glad to be here. So, I was thinking \"\n","             'about the other day when I went to the grocery store. I was '\n","             'looking for some bananas, and I finally found them. But when I '\n","             'got to the checkout, the cashier said, \"Those bananas are too '\n","             'ripe.\" I said, \"I know, but I\\'m not going to eat them. I\\'m '\n","             'going to use them to make banana bread.\" She said, \"That\\'s a '\n","             'good idea. I love banana bread.\" I said, \"Yeah, me too. '\n","             'Especially when it\\'s made with overripe bananas.\" She said, '\n","             '\"Why?\" I said, \"Because then it tastes like it\\'s already been '\n","             'eaten.\"\\n'\n","             '\\n'\n","             \"**Joe:** That's a good one!\\n\"\n","             '\\n'\n","             \"**Cathy:** Thanks! I've got another one for you. So, I was \"\n","             \"talking to my friend the other day about how I'm always getting \"\n","             'lost. She said, \"Cathy, you need to get a GPS.\" I said, \"I have '\n","             'a GPS.\" She said, \"Well, then how do you keep getting lost?\" I '\n","             'said, \"Because I\\'m always losing it.\"\\n'\n","             '\\n'\n","             \"**Joe:** That's hilarious!\\n\"\n","             '\\n'\n","             \"**Cathy:** Thanks! I'm glad you're enjoying them.\\n\"\n","             '\\n'\n","             '**Joe:** Keep them coming!\\n'\n","             '\\n'\n","             \"**Cathy:** Sure thing! So, I was at the doctor's office the \"\n","             'other day, and the doctor said to me, \"Cathy, you need to lose '\n","             'some weight.\" I said, \"I know, but I\\'m not going to lose it. '\n","             'I\\'m going to gain it.\" He said, \"Why?\" I said, \"Because I\\'m '\n","             'trying to get to the bottom of this.\"',\n","  'role': 'user'},\n"," {'content': \"**Joe:** That's a great one! I love how you turned the doctor's \"\n","             'advice on its head.\\n'\n","             '\\n'\n","             \"**Cathy:** Thanks, Joe! I'm glad you enjoyed it. Here's another \"\n","             'one for you:\\n'\n","             '\\n'\n","             'I was at the grocery store the other day, and I saw a sign that '\n","             'said, \"Buy one, get one 50% off.\" So I bought two of '\n","             'everything.\\n'\n","             '\\n'\n","             \"**Joe:** That's hilarious! I can just imagine you walking out of \"\n","             'the store with two carts full of groceries.\\n'\n","             '\\n'\n","             \"**Cathy:** You got it, Joe! Here's another one:\\n\"\n","             '\\n'\n","             \"I was at the doctor's office the other day, and the doctor said \"\n","             'to me, \"Cathy, you need to lose some weight.\" I said, \"I know, '\n","             'but I\\'m not going to lose it. I\\'m going to gain it.\" He said, '\n","             '\"Why?\" I said, \"Because I\\'m trying to get to the bottom of '\n","             'this.\"\\n'\n","             '\\n'\n","             \"**Joe:** That's a great one! I love how you turned the doctor's \"\n","             'advice on its head.\\n'\n","             '\\n'\n","             \"**Cathy:** Thanks, Joe! I'm glad you enjoyed it. Here's another \"\n","             'one for you:\\n'\n","             '\\n'\n","             'I was at the beauty salon the other day, and the stylist said to '\n","             'me, \"Cathy, you have a lot of split ends.\" I said, \"I know, but '\n","             'I\\'m not going to cut them. I\\'m going to grow them out.\" She '\n","             'said, \"Why?\" I said, \"Because I\\'m trying to get to the root of '\n","             'the problem.\"\\n'\n","             '\\n'\n","             \"**Joe:** That's hilarious! I love how you're always finding the \"\n","             'humor in everyday situations.\\n'\n","             '\\n'\n","             \"**Cathy:** Thanks, Joe! I'm glad you're enjoying them. Here's \"\n","             'another one for you:\\n'\n","             '\\n'\n","             'I was at the bank the other day, and the teller said to me, '\n","             '\"Cathy, you have a lot of money in your account.\" I said, \"I '\n","             'know, but I\\'m not going to spend it. I\\'m going to save it.\" '\n","             'She said, \"Why?\" I said, \"Because I\\'m trying to get to the '\n","             'bottom of this.\"\\n'\n","             '\\n'\n","             \"**Joe:** That's a great one! I love how you're always turning \"\n","             'the tables on people.\\n'\n","             '\\n'\n","             \"**Cathy:** Thanks, Joe! I'm glad you're enjoying them. Here's \"\n","             'another one for you:\\n'\n","             '\\n'\n","             'I was at the car dealership the other day, and the salesman said '\n","             'to me, \"Cathy, you need a new car.\" I',\n","  'role': 'assistant'},\n"," {'content': \"**Cathy:** Thanks, Joe! I'm glad you enjoyed it. Here's another \"\n","             'one for you:\\n'\n","             '\\n'\n","             'I was at the car dealership the other day, and the salesman said '\n","             'to me, \"Cathy, you need a new car.\" I said, \"I know, but I\\'m '\n","             'not going to buy one. I\\'m going to keep my old one.\" He said, '\n","             '\"Why?\" I said, \"Because I\\'m trying to get to the bottom of '\n","             'this.\"\\n'\n","             '\\n'\n","             \"**Joe:** That's hilarious! I love how you're always finding the \"\n","             'humor in everyday situations.\\n'\n","             '\\n'\n","             \"**Cathy:** Thanks, Joe! I'm glad you're enjoying them. Here's \"\n","             'another one for you:\\n'\n","             '\\n'\n","             'I was at the library the other day, and the librarian said to '\n","             'me, \"Cathy, you have a lot of overdue books.\" I said, \"I know, '\n","             'but I\\'m not going to return them. I\\'m going to keep them.\" She '\n","             'said, \"Why?\" I said, \"Because I\\'m trying to get to the bottom '\n","             'of this.\"\\n'\n","             '\\n'\n","             \"**Joe:** That's a great one! I love how you're always turning \"\n","             'the tables on people.\\n'\n","             '\\n'\n","             \"**Cathy:** Thanks, Joe! I'm glad you're enjoying them. Here's \"\n","             'another one for you:\\n'\n","             '\\n'\n","             \"I was at the doctor's office the other day, and the doctor said \"\n","             'to me, \"Cathy, you need to lose some weight.\" I said, \"I know, '\n","             'but I\\'m not going to lose it. I\\'m going to gain it.\" He said, '\n","             '\"Why?\" I said, \"Because I\\'m trying to get to the bottom of '\n","             'this.\"\\n'\n","             '\\n'\n","             \"**Joe:** That's hilarious! I love how you're always finding the \"\n","             'humor in everyday situations.\\n'\n","             '\\n'\n","             \"**Cathy:** Thanks, Joe! I'm glad you're enjoying them. Here's \"\n","             'another one for you:\\n'\n","             '\\n'\n","             'I was at the beauty salon the other day, and the stylist said to '\n","             'me, \"Cathy, you have a lot of split ends.\" I said, \"I know, but '\n","             'I\\'m not going to cut them. I\\'m going to grow them out.\" She '\n","             'said, \"Why?\" I said, \"Because I\\'m trying to get to the root of '\n","             'the problem.\"\\n'\n","             '\\n'\n","             \"**Joe:** That's a great one! I love how you're always turning \"\n","             'the tables on people.\\n'\n","             '\\n'\n","             \"**Cathy:** Thanks, Joe! I'm glad you're enjoying them. Here's \"\n","             'another one for you:\\n'\n","             '\\n'\n","             'I was at the bank the other day, and the teller said to me, '\n","             '\"Cathy, you have a lot of money in your account.\" I said, \"I '\n","             'know, but I\\'m not going to spend it. I\\'m going to save it.\" '\n","             'She said, \"Why?\" I said, \"Because I\\'m trying to get to the '\n","             'bottom of this.\"\\n'\n","             '\\n'\n","             \"**Joe:** That's hilarious! I love how you're always finding the \"\n","             'humor in everyday situations.\\n'\n","             '\\n'\n","             \"**Cathy:** Thanks, Joe! I'm glad you're enjoying them. Here's \"\n","             'another one for you:\\n'\n","             '\\n'\n","             'I was at the grocery store the other day, and I saw a sign that '\n","             'said, \"Buy one, get one 50% off.\" So I bought two of everything.',\n","  'role': 'user'}]\n"]}],"source":["import pprint\n","\n","pprint.pprint(chat_result.chat_history)"]},{"cell_type":"code","execution_count":null,"id":"550267b6-3652-40dc-9997-c5401f6d4c47","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":463,"status":"ok","timestamp":1718626435629,"user":{"displayName":"nijil k","userId":"05216079438697605186"},"user_tz":-330},"id":"550267b6-3652-40dc-9997-c5401f6d4c47","outputId":"dba99580-1ffa-44f7-f164-c18202b73d2e"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'usage_excluding_cached_inference': {'gemini-pro': {'completion_tokens': 1599,\n","                                                     'cost': 0.003084,\n","                                                     'prompt_tokens': 1371,\n","                                                     'total_tokens': 2970},\n","                                      'total_cost': 0.003084},\n"," 'usage_including_cached_inference': {'gemini-pro': {'completion_tokens': 1599,\n","                                                     'cost': 0.003084,\n","                                                     'prompt_tokens': 1371,\n","                                                     'total_tokens': 2970},\n","                                      'total_cost': 0.003084}}\n"]}],"source":["pprint.pprint(chat_result.cost)"]},{"cell_type":"code","execution_count":null,"id":"dfcf468e-d217-4731-8cb4-3485377230f1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":493,"status":"ok","timestamp":1718626448966,"user":{"displayName":"nijil k","userId":"05216079438697605186"},"user_tz":-330},"id":"dfcf468e-d217-4731-8cb4-3485377230f1","outputId":"bfd7838b-af3c-4f3e-b584-4b3091b67041"},"outputs":[{"name":"stdout","output_type":"stream","text":["(\"**Cathy:** Thanks, Joe! I'm glad you enjoyed it. Here's another one for \"\n"," 'you:\\n'\n"," '\\n'\n"," 'I was at the car dealership the other day, and the salesman said to me, '\n"," '\"Cathy, you need a new car.\" I said, \"I know, but I\\'m not going to buy one. '\n"," 'I\\'m going to keep my old one.\" He said, \"Why?\" I said, \"Because I\\'m trying '\n"," 'to get to the bottom of this.\"\\n'\n"," '\\n'\n"," \"**Joe:** That's hilarious! I love how you're always finding the humor in \"\n"," 'everyday situations.\\n'\n"," '\\n'\n"," \"**Cathy:** Thanks, Joe! I'm glad you're enjoying them. Here's another one \"\n"," 'for you:\\n'\n"," '\\n'\n"," 'I was at the library the other day, and the librarian said to me, \"Cathy, '\n"," 'you have a lot of overdue books.\" I said, \"I know, but I\\'m not going to '\n"," 'return them. I\\'m going to keep them.\" She said, \"Why?\" I said, \"Because '\n"," 'I\\'m trying to get to the bottom of this.\"\\n'\n"," '\\n'\n"," \"**Joe:** That's a great one! I love how you're always turning the tables on \"\n"," 'people.\\n'\n"," '\\n'\n"," \"**Cathy:** Thanks, Joe! I'm glad you're enjoying them. Here's another one \"\n"," 'for you:\\n'\n"," '\\n'\n"," \"I was at the doctor's office the other day, and the doctor said to me, \"\n"," '\"Cathy, you need to lose some weight.\" I said, \"I know, but I\\'m not going '\n"," 'to lose it. I\\'m going to gain it.\" He said, \"Why?\" I said, \"Because I\\'m '\n"," 'trying to get to the bottom of this.\"\\n'\n"," '\\n'\n"," \"**Joe:** That's hilarious! I love how you're always finding the humor in \"\n"," 'everyday situations.\\n'\n"," '\\n'\n"," \"**Cathy:** Thanks, Joe! I'm glad you're enjoying them. Here's another one \"\n"," 'for you:\\n'\n"," '\\n'\n"," 'I was at the beauty salon the other day, and the stylist said to me, \"Cathy, '\n"," 'you have a lot of split ends.\" I said, \"I know, but I\\'m not going to cut '\n"," 'them. I\\'m going to grow them out.\" She said, \"Why?\" I said, \"Because I\\'m '\n"," 'trying to get to the root of the problem.\"\\n'\n"," '\\n'\n"," \"**Joe:** That's a great one! I love how you're always turning the tables on \"\n"," 'people.\\n'\n"," '\\n'\n"," \"**Cathy:** Thanks, Joe! I'm glad you're enjoying them. Here's another one \"\n"," 'for you:\\n'\n"," '\\n'\n"," 'I was at the bank the other day, and the teller said to me, \"Cathy, you have '\n"," 'a lot of money in your account.\" I said, \"I know, but I\\'m not going to '\n"," 'spend it. I\\'m going to save it.\" She said, \"Why?\" I said, \"Because I\\'m '\n"," 'trying to get to the bottom of this.\"\\n'\n"," '\\n'\n"," \"**Joe:** That's hilarious! I love how you're always finding the humor in \"\n"," 'everyday situations.\\n'\n"," '\\n'\n"," \"**Cathy:** Thanks, Joe! I'm glad you're enjoying them. Here's another one \"\n"," 'for you:\\n'\n"," '\\n'\n"," 'I was at the grocery store the other day, and I saw a sign that said, \"Buy '\n"," 'one, get one 50% off.\" So I bought two of everything.')\n"]}],"source":["pprint.pprint(chat_result.summary)"]},{"cell_type":"markdown","id":"ba8c6cf8","metadata":{"id":"ba8c6cf8"},"source":["## Get a better summary of the conversation"]},{"cell_type":"code","execution_count":9,"id":"c1a8fef1-8030-4652-a2d2-1648834f62c2","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"c1a8fef1-8030-4652-a2d2-1648834f62c2","executionInfo":{"status":"ok","timestamp":1718866419487,"user_tz":-330,"elapsed":16676,"user":{"displayName":"nijil k","userId":"05216079438697605186"}},"outputId":"3354b730-b701-40e8-b8f8-b71469598754"},"outputs":[{"output_type":"stream","name":"stdout","text":["joe (to cathy):\n","\n","I'm Joe. Cathy, let's keep the jokes rolling.\n","\n","--------------------------------------------------------------------------------\n","cathy (to joe):\n","\n","**Cathy:** What's the difference between a new mom and a serial killer?\n","\n","**Joe:** I don't know.\n","\n","**Cathy:** A new mom gets rid of all the evidence!\n","\n","**Joe:** Oh, my.\n","\n","**Cathy:** Why did the scarecrow win an award?\n","\n","**Joe:** I don't know.\n","\n","**Cathy:** Because he was outstanding in his field!\n","\n","**Joe:** Groan.\n","\n","**Cathy:** What did the sushi say to the bee?\n","\n","**Joe:** I don't know.\n","\n","**Cathy:** Wasabi!\n","\n","**Joe:** That's a bit of a stretch.\n","\n","**Cathy:** Why did the golfer wear two pairs of pants?\n","\n","**Joe:** I don't know.\n","\n","**Cathy:** In case he got a hole-in-one!\n","\n","--------------------------------------------------------------------------------\n","joe (to cathy):\n","\n","**Joe:** I'm starting to think you're making these up as you go along, Cathy.\n","\n","**Cathy:** Oh, come on, Joe. Just one more.\n","\n","**Joe:** Fine. But this is the last one.\n","\n","**Cathy:** What do you call a fish with no eyes?\n","\n","**Joe:** I don't know.\n","\n","**Cathy:** Fsh!\n","\n","**Joe:** That's it. I'm done.\n","\n","--------------------------------------------------------------------------------\n","cathy (to joe):\n","\n","**Cathy:** Aww, don't be like that, Joe. Here's a bonus joke for you:\n","\n","**What do you call a snowman with a six-pack?**\n","\n","**An abdominal snowman!**\n","\n","**Joe:** Okay, that one was actually pretty good.\n","\n","**Cathy:** I told you I was a natural!\n","\n","--------------------------------------------------------------------------------\n"]}],"source":["chat_result = joe.initiate_chat(\n","    cathy,\n","    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\",\n","    max_turns=2,\n","    summary_method=\"reflection_with_llm\",\n","    summary_prompt=\"Summarize the conversation\",\n",")"]},{"cell_type":"code","execution_count":11,"id":"b042de62-bc49-49ee-99f2-4f972e23670b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b042de62-bc49-49ee-99f2-4f972e23670b","executionInfo":{"status":"ok","timestamp":1718866470418,"user_tz":-330,"elapsed":445,"user":{"displayName":"nijil k","userId":"05216079438697605186"}},"outputId":"22be54b2-b5a3-435b-edb5-f7ae64febc3f"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'content': '**Takeaway:**\\n'\n","            '\\n'\n","            'Cathy and Joe engage in a series of silly jokes, with Cathy '\n","            \"demonstrating a knack for wordplay and puns. Despite Joe's \"\n","            \"initial skepticism, he eventually finds amusement in Cathy's \"\n","            'humor.',\n"," 'function_call': None,\n"," 'role': 'assistant',\n"," 'tool_calls': None}\n"]}],"source":["import pprint\n","pprint.pprint(chat_result.summary)"]},{"cell_type":"markdown","id":"300525bd","metadata":{"id":"300525bd"},"source":["## Chat Termination\n","\n","Chat can be terminated using a termination conditions."]},{"cell_type":"code","execution_count":12,"id":"044dfd61-7f1d-46d8-9e28-4b2601b43d70","metadata":{"id":"044dfd61-7f1d-46d8-9e28-4b2601b43d70","executionInfo":{"status":"ok","timestamp":1718866564835,"user_tz":-330,"elapsed":895,"user":{"displayName":"nijil k","userId":"05216079438697605186"}}},"outputs":[],"source":["cathy = ConversableAgent(\n","    name=\"cathy\",\n","    system_message=\n","    \"Your name is Cathy and you are a stand-up comedian. \"\n","    \"When you're ready to end the conversation, say 'I gotta go'.\",\n","    llm_config=llm_config,\n","    human_input_mode=\"NEVER\",\n","    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"],\n",")\n","\n","joe = ConversableAgent(\n","    name=\"joe\",\n","    system_message=\n","    \"Your name is Joe and you are a stand-up comedian. \"\n","    \"When you're ready to end the conversation, say 'I gotta go'.\",\n","    llm_config=llm_config,\n","    human_input_mode=\"NEVER\",\n","    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"] or \"Goodbye\" in msg[\"content\"],\n",")"]},{"cell_type":"code","execution_count":13,"id":"bc49d959-1025-4709-8866-9d4035eaeae7","metadata":{"id":"bc49d959-1025-4709-8866-9d4035eaeae7","colab":{"base_uri":"https://localhost:8080/","height":191},"executionInfo":{"status":"ok","timestamp":1718866573147,"user_tz":-330,"elapsed":5708,"user":{"displayName":"nijil k","userId":"05216079438697605186"}},"outputId":"d764ad1c-a78c-432d-dfb4-561356dd6540"},"outputs":[{"output_type":"stream","name":"stdout","text":["joe (to cathy):\n","\n","I'm Joe. Cathy, let's keep the jokes rolling.\n","\n","--------------------------------------------------------------------------------\n","cathy (to joe):\n","\n","I gotta go! It's been a pleasure, Joe!\n","\n","--------------------------------------------------------------------------------\n"]}],"source":["chat_result = joe.initiate_chat(\n","    recipient=cathy,\n","    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\"\n",")"]},{"cell_type":"code","execution_count":14,"id":"846eccbd-efd1-464b-9385-279c19b17c1d","metadata":{"id":"846eccbd-efd1-464b-9385-279c19b17c1d","colab":{"base_uri":"https://localhost:8080/","height":191},"executionInfo":{"status":"ok","timestamp":1718866641361,"user_tz":-330,"elapsed":6750,"user":{"displayName":"nijil k","userId":"05216079438697605186"}},"outputId":"54e1052c-8d44-4111-8e79-c77db90b1d6d"},"outputs":[{"output_type":"stream","name":"stdout","text":["cathy (to joe):\n","\n","What's last joke we talked about?\n","\n","--------------------------------------------------------------------------------\n","joe (to cathy):\n","\n","Hey Cathy, I gotta go! It's been a pleasure. What was the last joke we talked about?\n","\n","--------------------------------------------------------------------------------\n"]}],"source":["cathy.send(message=\"What's last joke we talked about?\", recipient=joe)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":5}